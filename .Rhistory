unused_fn = NULL
)
pi%>%
tidyr::spread(key = "analyte",value = "value")
pi <- read_xlsx("iw.dm.extended.xlsx", col_names = TRUE)
pi_wider <- pivot_wider(data = pi,
names_from = "analyte",
values_from = "value")
pi_wider<-pivot_wider(
pi,
names_from = "analyte",
names_repair = "check_unique",
values_from = "value",
values_fill = NULL,
values_fn = NULL,
unused_fn = NULL
)
pi_wider<- pi%>%
tidyr::spread(key = "analyte",value = "value")
View(pi_wider)
pi_wider %>%
mutate(val = true) %>%
pivot_wider(names_from = "analyte",values_from = value,
values_fill = list(val = false))
pi_wider %>%
mutate(val = true) %>%
pivot_wider(names_from = "analyte",
values_from = "value",
values_fill = list(val = false))
pi_wider %>%
mutate(val = true) %>%
pivot_wider(names_from = "analyte",
values_from = "value",
values_fill = list("value "= false))
pi_wider %>%
mutate(value = true) %>%
pivot_wider(names_from = "analyte",
values_from = "value",
values_fill = list(val = false))
pi_wider %>%
mutate(value = TRUE) %>%
pivot_wider(names_from = "analyte",
values_from = "value",
values_fill = list(val = false))
pi_wider<- pi %>%
mutate(value = TRUE) %>%
pivot_wider(names_from = "analyte",
values_from = "value",
values_fill = list(val = false))
pi_wider<- pi %>%
mutate(value = TRUE) %>%
pivot_wider(names_from = "analyte",
values_from = "value",
values_fill = list(val = FALSE))
cast_data = cast(pi, analyte~value)
library(MASS)
library(reshape2)
library(reshape)
cast_data = cast(pi, analyte~value)
View(cast_data)
pi_wider <- pivot_wider(data = pi,
names_from = "analyte",
values_from = "value", "Cf")
pi <- read_xlsx("iw.dm.extended.xlsx", col_names = TRUE)
pi_wider <- pivot_wider(data = pi,
names_from = "analyte",
values_from = "value", "Cf")
View(pi)
pi_wider <- pivot_wider(data = pi,
names_from = "analyte",
values_from = "Cf")
View(pi_wider)
pi_short<- pi[c(2:6, 8, 10, 11, 12:14, 17, 17, 20)]
View(pi_short)
pi_wider <- pivot_wider(data = pi_short,
names_from = "analyte",
values_from = "Cf")
pi_short<- pi[c(2:6, 8, 10, 11, 12:14, 17, 18, 20)]
pi_wider <- pivot_wider(data = pi_short,
names_from = "analyte",
values_from = "Cf")
View(pi_short)
pi_short<- pi[c(2:6, 8, 10, 11, 12:14, 17, 20)]
pi_wider <- pivot_wider(data = pi_short,
names_from = "analyte",
values_from = "Cf")
View(pi_wider)
pi_wider$Pb)^(1/19)
)
pi_wider$Pb)^(1/19)
pi_wider$Pb)^(1/19))
pi_wider$pollution_index<- with (pi-wider, ((pi_wider$Be+
pi_wider$Al*
pi_wider$V*
pi_wider$Cr*
pi_wider$Mn*
pi_wider$Fe*
pi_wider$Co*
pi_wider$Ni*
pi_wider$Cu*
pi_wider$Zn*
pi_wider$As*
pi_wider$Se*
pi_wider$Mo*
pi_wider$Ag*
pi_wider$Cd*
pi_wider$Sn*
pi_wider$Sb*
pi_wider$Ba*
pi_wider$Pb)^(1/19)))
pi_wider$pollution_index<- with (pi-wider, ((pi_wider$Be*
pi_wider$Al*
pi_wider$V*
pi_wider$Cr*
pi_wider$Mn*
pi_wider$Fe*
pi_wider$Co*
pi_wider$Ni*
pi_wider$Cu*
pi_wider$Zn*
pi_wider$As*
pi_wider$Se*
pi_wider$Mo*
pi_wider$Ag*
pi_wider$Cd*
pi_wider$Sn*
pi_wider$Sb*
pi_wider$Ba*
pi_wider$Pb)^(1/19)))
pi_wider$pollution_index<- with (pi_wider, ((pi_wider$Be*
pi_wider$Al*
pi_wider$V*
pi_wider$Cr*
pi_wider$Mn*
pi_wider$Fe*
pi_wider$Co*
pi_wider$Ni*
pi_wider$Cu*
pi_wider$Zn*
pi_wider$As*
pi_wider$Se*
pi_wider$Mo*
pi_wider$Ag*
pi_wider$Cd*
pi_wider$Sn*
pi_wider$Sb*
pi_wider$Ba*
pi_wider$Pb)^(1/19)))
View(pi_wider)
write.csv(pi_wider, file= "pollution_load", col.names= TRUE, row.names=TRUE)
write.csv(pi_wider, file= "pollution_load.csv", col.names= TRUE, row.names=TRUE)
write.csv(pi_wider, file= "pollution_load.csv")
library(car)
library(readxl)
library(tidyverse)
library(ggplot2)
library(EnvStats)
library(lme4)
library(lmerTest)
library(performance)
library(effects)
library(ggeffects)
library(ggpubr)
library(emmeans)
library(multcomp)
library(patchwork)
#set working directory----
#setwd("/users/godsgiftnkechichukwuonye/Documents/GitHub/WorkingFiles/data/data_processing")
setwd("~/Documents/GitHub/ProjectHarvest/WorkingFiles//data/data_processing")
#load libraries ----
library(readxl) #read excel files
library(tidyverse)
library(ggplot2)
iw.dm <- read_xlsx("~/Documents/GitHub/ProjectHarvest/WorkingFiles/data/data_clean/IW_DM_Y123.xlsx", sheet = "Corrected")
##
###
###
###
###
###
###
#add period and season variables
iw.dm$period <- iw.dm$samplings
iw.dm$season <- iw.dm$samplings
#redefine them
iw.dm[iw.dm$period=="First Winter",]$period <- "First"
iw.dm[iw.dm$period=="Last Winter",]$period <- "Last"
iw.dm[iw.dm$period=="First Monsoon",]$period <- "First"
iw.dm[iw.dm$period=="Last Monsoon",]$period <- "Last"
iw.dm[iw.dm$season=="First Winter",]$season <- "Winter"
iw.dm[iw.dm$season=="Last Winter",]$season <- "Winter"
iw.dm[iw.dm$season=="First Monsoon",]$season <- "Monsoon"
iw.dm[iw.dm$season=="Last Monsoon",]$season <- "Monsoon"
#changing year #Make a new variable with this
iw.dm$year <- iw.dm$sampling_year
iw.dm[iw.dm$year=="2017-2018",]$year <- "Water Year 1"
iw.dm[iw.dm$year=="2018-2019",]$year <- "Water Year 2"
iw.dm[iw.dm$year=="2019-2020",]$year <- "Water Year 3"
#remove field blanks. to remove anything, type !="Value" to remove them.
iw.dm <- iw.dm[iw.dm$type!="B", ]
#remove ATS samples because ATS samples are not included in PH research.
iw.dm <- iw.dm[iw.dm$site!="ATS1", ]
#remove year 3 monsoon samples
iw.dm$ssnyear <- paste(iw.dm$season, iw.dm$year)
iw.dm <- iw.dm[iw.dm$ssnyear!="Monsoon Water Year 3", ]
#confirm correct order of categorical variables
#iw.dm$samplings <- factor(iw.dm$samplings, levels = c("FW", "LW", "FM", "LM"))
iw.dm$samplings <- factor(iw.dm$samplings, levels = c("First Winter", "Last Winter", "First Monsoon", "Last Monsoon"))
iw.dm$period <- factor(iw.dm$period, levels = c("First", "Last"))
iw.dm$season <- factor(iw.dm$season, levels = c("Winter", "Monsoon"))
iw.dm$sampling_year <- factor(iw.dm$sampling_year, levels = c("Water Year 1", "Water Year 2", "Water Year 3"))
iw.dm$community <- factor(iw.dm$community, levels = c("Dewey-Humboldt", "Globe/Miami", "Hayden/Winkelman", "Tucson"))
iw.pHec <- read_xlsx("~/Documents/GitHub/ProjectHarvest/WorkingFiles/data/data_clean/IW_pHEC_Y123.xlsx", sheet = 1, col_names = TRUE)
iw.pHec <- iw.pHec[iw.pHec$type!="B",] #removing field blanks
iw.dm <- full_join(iw.dm, iw.pHec, by = c("sample.name", "type")) #joins the phec data with the original iw.dm we had before
iw.dm <- iw.dm[!is.na(iw.dm$community),]
# na.omit(iw.dm$community)
#add mining community vs urban community
iw.dm$landuse <- "Mining Community"
iw.dm[iw.dm$community=="Tucson",]$landuse <- "Urban Community"
#longer ----
iw.dm.long <- pivot_longer(iw.dm,
cols = Be:Pb,
values_to = "value",
names_to = "analyte")
pli <- read.csv("~/Documents/GitHub/ProjectHarvest/WorkingFiles/data/data_processing/pollution_load_selected_analytes.csv")
iw.dm$pli <- pli$pollution_index_selected_analytes
pli_dat<- pli[-c(19,39),]
pli_dat <- pli_dat[pli_dat$site!="H222",]
pli_short<-  pli_dat[, -c(15, 19, 25, 26, 28, 29)]
pli_dat2<- pivot_longer(pli_short,
cols = Be:Pb,
values_to = "concentration_factor",
names_to = "analytes")
com <- read_xlsx("~/Documents/GitHub/ProjectHarvest/WorkingFiles/data/data_processing/LATLOGSITE.xlsx", sheet = "community", col_names = TRUE)
iw.dm <- full_join(iw.dm, com, by = c("site"))
iw.dm <- iw.dm[!is.na(iw.dm$mlod.name),]
#add proximity to cfactor dataframe
pli_dat3 <- full_join(pli_dat2, com, by = c("site"))
pli_dat3 <- pli_dat3[!is.na(pli_dat3$mlod.name),]
pli_dat4<- pivot_wider(pli_dat3,
values_from = "concentration_factor",
names_from= "analytes")
#outliers ----
#remove samples 19 and 39 from analysis because they were outliers based on MFA and remove all samples from H22 because they are a proximity outlier south of Winkelman
#G428IWA23-20190730 and H209IWA23-20190709
iw.dm <- iw.dm[-c(19,39),]
iw.dm <- iw.dm[iw.dm$site!="H222",]
standards <- read_xlsx("~/Documents/GitHub/ProjectHarvest/WorkingFiles/data/data_processing/Standards.xlsx", sheet = "standards", col_names = TRUE)
View(standards)
ex.dat <- full_join(iw.dm.long, standards, by = c("analyte"))
View(ex.dat)
ex.dat.long <- pivot_longer(data = ex.dat,
cols = PB:LDW,
values_to = "standard_value",
names_to = "standard")
ex.dat.long$exceedance <- ifelse(ex.dat.long$value > ex.dat.long$standard_value,1,0)
View(ex.dat.long)
ex.dat.long <- subset(ex.dat.long, select = -c(standard_value))
View(ex.dat.long)
ex.dat.long <- ex.dat.long %>%
drop_na(exceedance)
cols <- c("analyte", "standard")
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarize(n = n(),
min = min(.data[[exceedance]]),
max = max(.data[[exceedance]]),
median = median(.data[[exceedance]]),
mean = mean(.data[[exceedance]]),
sd = sd(.data[[exceedance]])
,
gmean = geoMean(.data[[exceedance]]),
gsd = geoSD(.data[[exceedance]])
)
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n())
View(sumtable)
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum())
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance))
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = sum(exceedance)/n()*100)
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = paste(sum(exceedance)/n()*100, "%"))
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = paste(signif(sum(exceedance)/n()*100, 2), "%"))
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = paste(signif(sum(exceedance)/n()*100, 2), "%", sep =""))
View(ex.dat.long)
#longer ----
iw.dm.long <- pivot_longer(iw.dm,
cols = Be:Pb,
values_to = "value",
names_to = "analyte")
#join standard data to contaminant data, this repeats the standard data for each analyte for each sample
ex.dat <- full_join(iw.dm.long, standards, by = c("analyte"))
#make longer
ex.dat.long <- pivot_longer(data = ex.dat,
cols = PB:LDW,
values_to = "standard_value",
names_to = "standard")
#calculate exceedance
ex.dat.long$exceedance <- ifelse(ex.dat.long$value > ex.dat.long$standard_value,1,0)
#remove standard value for ease of making wider
ex.dat.long <- subset(ex.dat.long, select = -c(standard_value))
#remove NAs for analytes that do not have standards
ex.dat.long <- ex.dat.long %>%
drop_na(exceedance)
#summary ----
#name subset columns
cols <- c("analyte", "standard")
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = paste(signif(sum(exceedance)/n()*100, 2), "%", sep =""))
sumtable.wide <- subset(sumtable, select = -c("n", "exceedance_n"))
sumtable.wide <- subset(sumtable, select = -c("n", "exceedances_n"))
sumtable.wide <- subset(sumtable, select = -c(n, exceedances_n))
View(sumtable.wide)
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable.small,
names_from = "standard",
values_from = "exceedances_freq")
#summary ----
#name subset columns
cols <- c("analyte", "standard", "community")
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = paste(signif(sum(exceedance)/n()*100, 2), "%", sep =""))
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable.small,
names_from = "standard",
values_from = "exceedances_freq")
standards <- read_xlsx("~/Documents/GitHub/ProjectHarvest/WorkingFiles/data/data_processing/Standards.xlsx", sheet = "standards", col_names = TRUE)
#join standard data to contaminant data, this repeats the standard data for each analyte for each sample
ex.dat <- full_join(iw.dm.long, standards, by = c("analyte"))
#make longer
ex.dat.long <- pivot_longer(data = ex.dat,
cols = PB:LDW,
values_to = "standard_value",
names_to = "standard")
#calculate exceedance
ex.dat.long$exceedance <- ifelse(ex.dat.long$value > ex.dat.long$standard_value,1,0)
#remove standard value for ease of making wider
ex.dat.long <- subset(ex.dat.long, select = -c(standard_value))
#remove NAs for analytes that do not have standards
ex.dat.long <- ex.dat.long %>%
drop_na(exceedance)
#summary ----
#name subset columns
cols <- c("analyte", "standard", "community")
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = paste(signif(sum(exceedance)/n()*100, 2), "%", sep =""))
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable.small,
names_from = "standard",
values_from = "exceedances_freq")
#summary ----
#name subset columns
cols <- c("analyte", "standard")
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = paste(signif(sum(exceedance)/n()*100, 2), "%", sep =""))
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable.small,
names_from = "standard",
values_from = "exceedances_freq")
view(sumtable.wide)
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = signif(sum(exceedance)/n()*100, 2))
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable.small,
names_from = "standard",
values_from = "exceedances_freq")
view(sumtable.wide)
#summary ----
#name subset columns
cols <- c("analyte", "standard", "community", "samplings", "sampling_year")
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = signif(sum(exceedance)/n()*100, 2))
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable.small,
names_from = "standard",
values_from = "exceedances_freq")
view(sumtable.wide)
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = signif(sum(exceedance)/n()*100, 2))
sumtable.wide <- pivot_wider(data = sumtable.small,
names_from = "standard",
values_from = "exceedances_freq")
view(sumtable.wide)
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = signif(sum(exceedance)/n()*100, 2))
sumtable.wide <- pivot_wider(data = sumtable,
names_from = "standard",
values_from = "exceedances_freq")
View(sumtable.wide)
install.packages("aod")
library(aod)
ex.dat.long[ex.dat.long$standard=="AI",]
e1 <- glm(data = ex.dat.long[ex.dat.long$standard=="AI",],
exceedance ~ season + community + analyte,
family = "binomial")
summary(ei)
summary(e1)
e1 <- glm(data = ex.dat.long[ex.dat.long$standard=="AI",],
exceedance ~ season,
family = "binomial")
summary(e1)
exp(coef(e1))
exp(-4.7431 + .8778)/(1+(exp(-4.7431 + .8778))
)
exp(-4.7431)/(1+(exp(-4.7431)))
#summary ----
#name subset columns
cols <- c("season", "standard")
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = signif(sum(exceedance)/n()*100, 2))
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable,
names_from = "standard",
values_from = "exceedances_freq")
view(sumtable.wide)
e1 <- glm(data = ex.dat.long[ex.dat.long$standard=="AI",],
exceedance ~ season + community,
family = "binomial")
summary(e1)
plot(e1)
check_model(e1)
#summary ----
#name subset columns
cols <- c("standard", "analyte")
#calculate counts and percentages of the whole
sumtable <- ex.dat.long %>%
group_by(across(all_of(cols))) %>%
summarise(n = n(),
exceedances_n = sum(exceedance),
exceedances_freq = signif(sum(exceedance)/n()*100, 2))
sumtable.small <- subset(sumtable, select = -c(n, exceedances_n))
sumtable.wide <- pivot_wider(data = sumtable,
names_from = "standard",
values_from = "exceedances_freq")
view(sumtable.wide)
e1 <- glm(data = ex.dat.long[ex.dat.long$standard=="AI"&ex.dat.long$analyte=="Cu",],
exceedance ~ season + community,
family = "binomial")
summary(e1)
check_model(e1)
exp(coef(e1))
performance(e1)
e2 <- glm(data = ex.dat.long[ex.dat.long$standard=="AI"&ex.dat.long$analyte=="Cu",],
exceedance ~ season,
family = "binomial")
summary(e2)
check_model(e2)
view(ex.dat.long)
performance(e2)
performance(e2, e1)
anova(e1, e2)
aov(e1, e2)
exp(coef(e2))
